{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import algo\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['Pilot_1', 'Pilot_2', 'Pilot_4', 'Pilot_5', 'Pilot_6', 'Pilot_7', 'Pilot_8', 'Pilot_9', 'Pilot_10', 'Pilot_11', 'Pilot_12', 'Pilot_13', 'Pilot_14', 'Pilot_15', 'Pilot_17', 'Pilot_18', 'Pilot_19', 'Pilot_20', 'Pilot_21']\n",
    "PATTERN = 'Overlay'\n",
    "SINGLEOBJ = True\n",
    "subj_path = ['../../Experiments/data/Two_Obj/' + PATTERN + '/' + sub + '/' for sub in subjects]\n",
    "nb_subj = len(subjects)\n",
    "bads = [['A30', 'B25'], ['B25'], ['B25'], [], ['A31', 'B31'], ['B25'], ['A30', 'B25'], ['A30', 'B25'], ['B25'], ['B25', 'B26'], ['A30', 'B25'], ['B31'], ['B25', 'A23'], ['A30', 'B25'], ['B25'], ['B25'], ['A30', 'B25'], ['A30', 'B25'], ['B25']]\n",
    "fsStim = 30\n",
    "feats_path_folder = '../Feat_Multi/features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_ONLY = True\n",
    "ALL_NEW = False\n",
    "eeg_multisubj_list, eog_multisubj_list, feat_all_att_list, feat_all_unatt_list, gaze_multisubj_list, fs, len_seg_list = utils.load_data(subj_path, fsStim, bads, feats_path_folder, PATTERN, singleobj=False, LOAD_ONLY=LOAD_ONLY, ALL_NEW=ALL_NEW)\n",
    "eeg_multisubj_list_SO, eog_multisubj_list_SO, feat_all_list_SO, _, gaze_multisubj_list_SO, fs, len_seg_list_SO = utils.load_data(subj_path, fsStim, bads, feats_path_folder, PATTERN, singleobj=True, LOAD_ONLY=LOAD_ONLY, ALL_NEW=ALL_NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaze_velocity_list = [utils.calcu_gaze_velocity(gaze) for gaze in gaze_multisubj_list]\n",
    "gaze_coords_list = [gaze[:,0:2,:] for gaze in gaze_multisubj_list]\n",
    "saccade_multisubj_list = [np.expand_dims(gaze[:,2,:], axis=1) for gaze in gaze_multisubj_list]\n",
    "blink_multisubj_list = [np.expand_dims(gaze[:,3,:], axis=1) for gaze in gaze_multisubj_list]\n",
    "saccade_multisubj_list = utils.refine_saccades(saccade_multisubj_list, blink_multisubj_list)\n",
    "eog_velocity_list = [utils.calcu_gaze_vel_from_EOG(eog) for eog in eog_multisubj_list]\n",
    "gaze_velocity_list = [utils.interpolate_blinks(gaze_velocity, blink) for gaze_velocity, blink in zip(gaze_velocity_list, blink_multisubj_list)]\n",
    "gaze_coords_list = [utils.interpolate_blinks(gaze_coords, blink) for gaze_coords, blink in zip(gaze_coords_list, blink_multisubj_list)]\n",
    "eog_velocity_list = [utils.interpolate_blinks(eog_velocity, blink) for eog_velocity, blink in zip(eog_velocity_list, blink_multisubj_list)] # blinks are not removed as cleanly as in the gaze data\n",
    "mod_list = [eeg_multisubj_list, eog_multisubj_list, gaze_coords_list, gaze_velocity_list, eog_velocity_list, saccade_multisubj_list, feat_all_att_list, feat_all_unatt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SINGLEOBJ: # if include single object data in the analysis\n",
    "    gaze_velocity_list_SO = [utils.calcu_gaze_velocity(gaze) for gaze in gaze_multisubj_list_SO]\n",
    "    gaze_coords_list_SO = [gaze[:,0:2,:] for gaze in gaze_multisubj_list_SO]\n",
    "    saccade_multisubj_list_SO = [np.expand_dims(gaze[:,2,:], axis=1) for gaze in gaze_multisubj_list_SO]\n",
    "    blink_multisubj_list_SO = [np.expand_dims(gaze[:,3,:], axis=1) for gaze in gaze_multisubj_list_SO]\n",
    "    saccade_multisubj_list_SO = utils.refine_saccades(saccade_multisubj_list_SO, blink_multisubj_list_SO)\n",
    "    eog_velocity_list_SO = [utils.calcu_gaze_vel_from_EOG(eog) for eog in eog_multisubj_list_SO]\n",
    "    gaze_velocity_list_SO = [utils.interpolate_blinks(gaze_velocity, blink) for gaze_velocity, blink in zip(gaze_velocity_list_SO, blink_multisubj_list_SO)]\n",
    "    gaze_coords_list_SO = [utils.interpolate_blinks(gaze_coords, blink) for gaze_coords, blink in zip(gaze_coords_list_SO, blink_multisubj_list_SO)]\n",
    "    eog_velocity_list_SO = [utils.interpolate_blinks(eog_velocity, blink) for eog_velocity, blink in zip(eog_velocity_list_SO, blink_multisubj_list_SO)] # blinks are not removed as cleanly as in the gaze data\n",
    "    mod_list = [eeg_multisubj_list, eog_multisubj_list, gaze_coords_list, gaze_velocity_list, eog_velocity_list, saccade_multisubj_list, feat_all_att_list, feat_all_unatt_list, eeg_multisubj_list_SO, eog_multisubj_list_SO, gaze_coords_list_SO, gaze_velocity_list_SO, eog_velocity_list_SO, saccade_multisubj_list_SO, feat_all_list_SO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the alignment between eog and gaze. The synchronization is good if the peaks of two signals (eye blinks) are aligned.\n",
    "# subj_to_check = 'Pilot_20'\n",
    "# subj_ID = subjects.index(subj_to_check)\n",
    "# utils.check_alignment(subj_ID, eog_multisubj_list, gaze_multisubj_list, nb_points=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RemoveSC = True # remove shot cuts\n",
    "if RemoveSC:\n",
    "    mod_list = [[utils.remove_shot_cuts(d, fs) for d in sublist] for sublist in mod_list]\n",
    "if not SINGLEOBJ:\n",
    "    [eeg_multisubj_list, eog_multisubj_list, gaze_coords_list, gaze_velocity_list, eog_velocity_list, saccade_multisubj_list, feat_all_att_list, feat_all_unatt_list] = mod_list\n",
    "else:\n",
    "    [eeg_multisubj_list, eog_multisubj_list, gaze_coords_list, gaze_velocity_list, eog_velocity_list, saccade_multisubj_list, feat_all_att_list, feat_all_unatt_list, eeg_multisubj_list_SO, eog_multisubj_list_SO, gaze_coords_list_SO, gaze_velocity_list_SO, eog_velocity_list_SO, saccade_multisubj_list_SO, feat_all_list_SO] = mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get object optical flow and object temporal contrast\n",
    "objflow_att_list = [feats[:,8] for feats in feat_all_att_list]\n",
    "objtempctr_att_list = [feats[:,17] for feats in feat_all_att_list]\n",
    "objflow_unatt_list = [feats[:,8] for feats in feat_all_unatt_list]\n",
    "objtempctr_unatt_list = [feats[:,17] for feats in feat_all_unatt_list]\n",
    "if SINGLEOBJ:\n",
    "    objflow_list_SO = [feats[:,8] for feats in feat_all_list_SO]\n",
    "    objtempctr_list_SO = [feats[:,17] for feats in feat_all_list_SO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features being used in the analysis: object optical flow\n",
    "feat_att_list = objflow_att_list\n",
    "feat_unatt_list = objflow_unatt_list\n",
    "# Dictionary for modalities\n",
    "modal_dict = {'EEG': eeg_multisubj_list, 'EOG': eog_multisubj_list, 'GAZE': gaze_coords_list, 'GAZE_V': gaze_velocity_list\n",
    "              , 'EOG_V': eog_velocity_list, 'SACC': saccade_multisubj_list}\n",
    "\n",
    "if SINGLEOBJ:\n",
    "    feat_list_SO = objflow_list_SO\n",
    "    modal_dict_SO = {'EEG': eeg_multisubj_list_SO, 'EOG': eog_multisubj_list_SO, 'GAZE': gaze_coords_list_SO, 'GAZE_V': gaze_velocity_list_SO\n",
    "                  , 'EOG_V': eog_velocity_list_SO, 'SACC': saccade_multisubj_list_SO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters in CCA; L_EEG and offset_EEG are not only used for EEG but also for other modalities\n",
    "L_EEG = 3 \n",
    "L_Stim = int(fsStim/2) \n",
    "offset_EEG = 1 \n",
    "offset_Stim = 0 \n",
    "trial_len_list = list(range(15, 75, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders for saving figures and tables; Currently there are no figures for modalities other than EEG, but the folders are still there.\n",
    "figure_dirs = {}\n",
    "table_dirs = {}\n",
    "CLEAR = False # clear the content if set to True\n",
    "for data_type in modal_dict.keys():\n",
    "    figure_path = f'figures/{PATTERN}/{data_type}/'\n",
    "    utils.create_dir(figure_path, CLEAR)\n",
    "    figure_dirs[data_type] = figure_path\n",
    "    table_path = f'tables/{PATTERN}/{data_type}/'\n",
    "    utils.create_dir(table_path, CLEAR)\n",
    "    table_dirs[data_type] = table_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_att_or_unatt_LVO(Subj_ID, eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT, eeg_ori_list=None, dim_list_EEG=None, dim_list_Stim=None, n_components=3, saccade_multisubj_list=None, V_eeg=None, V_Stim=None, PLOT=False, figure_dir=None, SAVERES=False, table_dir=None, OVERWRITE=False, feat_name='ObjFlow', COMBINE_ATT_UNATT=False):\n",
    "    '''\n",
    "    TASK: Perform CCA analysis for attended or unattended features and save forward models and correlations\n",
    "\n",
    "    Inputs that need further explanation:\n",
    "    TRAIN_WITH_ATT: True if training with attended features, False if training with unattended features\n",
    "    eeg_ori_list: Original EEG data, necessary for calculating the forward model when the input eeg_multisubj_list is already hankelized (e.g., due to spatial-temporal regression)\n",
    "    dim_list_EEG: If the input eeg_multisubj_list is actually a stack of EEG and other modalities, dim_list_EEG is a list of the dimensions of each modality. E.g., [64, 4] for stacked EEG and EOG. Always put EEG at the first place.\n",
    "    dim_list_Stim: Similar to dim_list_EEG, but for the dimensions of the stimulus features.\n",
    "    saccade_multisubj_list: Saccade data. A mask will be created if saccade data is provided to exclude the time points around saccades.\n",
    "    V_eeg, V_Stim: If want to use pretrained filters trained from single object data, provide the filters here.\n",
    "    PLOT: True if want to plot the forward models [only applicable for EEG], False otherwise\n",
    "    SAVERES: True if want to save the results in a table, False otherwise\n",
    "    OVERWRITE: True if want to overwrite the existing results in the table, False otherwise\n",
    "    '''\n",
    "    eeg_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_multisubj_list]\n",
    "    eeg_ori_onesubj_list = [eeg_ori[:,:,Subj_ID] for eeg_ori in eeg_ori_list] if eeg_ori_list is not None else None \n",
    "    feat_att_list = [feat_att[:,:,Subj_ID] for feat_att in feat_att_list] if np.ndim(feat_att_list[0]) == 3 else feat_att_list\n",
    "    feat_unatt_list = [feat_unatt[:,:,Subj_ID] for feat_unatt in feat_unatt_list] if np.ndim(feat_unatt_list[0]) == 3 else feat_unatt_list\n",
    "    if saccade_multisubj_list is not None:\n",
    "        saccade_onesubj_list = [saccade[:,:,Subj_ID] for saccade in saccade_multisubj_list]\n",
    "        mask_list = utils.get_mask_list(saccade_onesubj_list, before=10, after=20)\n",
    "    else:\n",
    "        mask_list = None\n",
    "    CCA = algo.CanonicalCorrelationAnalysis(eeg_onesubj_list, feat_att_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, dim_list_EEG=dim_list_EEG, dim_list_Stim=dim_list_Stim, n_components=n_components, mask_list=mask_list)\n",
    "    corr_att_fold, corr_unatt_fold, sig_corr_fold, sig_corr_pool, forward_model_fold = CCA.att_or_unatt_LVO(feat_unatt_list, TRAIN_WITH_ATT, V_eeg=V_eeg, V_Stim=V_Stim, EEG_ori_list=eeg_ori_onesubj_list, COMBINE_ATT_UNATT=COMBINE_ATT_UNATT)\n",
    "    train_type = 'SO' if V_eeg is not None else 'Att' if TRAIN_WITH_ATT else 'Unatt'\n",
    "    ifmask = True if mask_list is not None else False\n",
    "    if PLOT:\n",
    "        figure_name = f\"{figure_dir}{feat_name}_Subj_{Subj_ID+1}_Train_{train_type}_Mask_{ifmask}_Folds.png\"\n",
    "        # if FM_org is not None:\n",
    "        #     forward_model_fold = [utils.F_organize(forward_model, FM_org[0], FM_org[1]) for forward_model in forward_model_fold]\n",
    "        utils.plot_spatial_resp_fold(forward_model_fold, corr_att_fold, corr_unatt_fold, sig_corr_fold, figure_name, AVG=False)\n",
    "        utils.plot_spatial_resp_fold(forward_model_fold, corr_att_fold, corr_unatt_fold, sig_corr_pool, figure_name, AVG=True)\n",
    "    if SAVERES:\n",
    "        table_name = table_dir + f'{feat_name}_Corr_Train_{train_type}_Mask_{ifmask}.csv'\n",
    "        utils.save_corr_df(table_name, sig_corr_pool, corr_att_fold, corr_unatt_fold, Subj_ID, OVERWRITE)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_compete_trials_LVO(Subj_ID, eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir, dim_list_EEG=None, dim_list_Stim=None, saccade_multisubj_list=None, BOOTSTRAP=True, V_eeg=None, V_Stim=None, n_components=3, nb_comp_into_account=2, signifi_level=False, message=True, OVERWRITE=False, feat_name='ObjFlow', COMBINE_ATT_UNATT=False):\n",
    "    '''\n",
    "    TASK: Determine the attended feature from the unattended feature using CCA and evaluate the performance\n",
    "\n",
    "    Inputs that need further explanation:\n",
    "    TRAIN_WITH_ATT: True if training with attended features, False if training with unattended features\n",
    "    eeg_ori_list: Original EEG data, necessary for calculating the forward model when the input eeg_multisubj_list is already hankelized (e.g., due to spatial-temporal regression)\n",
    "    dim_list_EEG: If the input eeg_multisubj_list is actually a stack of EEG and other modalities, dim_list_EEG is a list of the dimensions of each modality. E.g., [64, 4] for stacked EEG and EOG. Always put EEG at the first place.\n",
    "    dim_list_Stim: Similar to dim_list_EEG, but for the dimensions of the stimulus features.\n",
    "    saccade_multisubj_list: Saccade data. A mask will be created if saccade data is provided to exclude the time points around saccades.\n",
    "    BOOTSTRAP: True if selecting trials with given length randomly (wiith overlap), False if dividing the trials without overlap\n",
    "    V_eeg, V_Stim: If want to use pretrained filters trained from single object data, provide the filters here.\n",
    "    nb_comp_into_account: Number of components into account when calculating the accuracy\n",
    "    OVERWRITE: True if want to overwrite the existing results in the table, False otherwise\n",
    "    '''\n",
    "    res = []\n",
    "    eeg_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_multisubj_list]\n",
    "    feat_att_list = [feat_att[:,:,Subj_ID] for feat_att in feat_att_list] if np.ndim(feat_att_list[0]) == 3 else feat_att_list\n",
    "    feat_unatt_list = [feat_unatt[:,:,Subj_ID] for feat_unatt in feat_unatt_list] if np.ndim(feat_unatt_list[0]) == 3 else feat_unatt_list\n",
    "    if saccade_multisubj_list is not None:\n",
    "        saccade_onesubj_list = [saccade[:,:,Subj_ID] for saccade in saccade_multisubj_list]\n",
    "        mask_list = utils.get_mask_list(saccade_onesubj_list, before=10, after=20)\n",
    "    else:\n",
    "        mask_list = None\n",
    "    ifmask = True if mask_list is not None else False\n",
    "    CCA = algo.CanonicalCorrelationAnalysis(eeg_onesubj_list, feat_att_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, dim_list_EEG=dim_list_EEG, dim_list_Stim=dim_list_Stim, n_components=n_components, mask_list=mask_list, signifi_level=signifi_level, message=message)\n",
    "    for trial_len in trial_len_list:\n",
    "        print('Trial length: ', trial_len)\n",
    "        corr_att_eeg, corr_unatt_eeg = CCA.att_or_unatt_LVO_trials(feat_unatt_list, trial_len=trial_len, BOOTSTRAP=BOOTSTRAP, V_eeg=V_eeg, V_Stim=V_Stim, COMBINE_ATT_UNATT=COMBINE_ATT_UNATT)\n",
    "        acc, _, _, _, _= utils.eval_compete(corr_att_eeg, corr_unatt_eeg, TRAIN_WITH_ATT=True, nb_comp_into_account=nb_comp_into_account)\n",
    "        res.append(acc)\n",
    "    train_type = 'SO' if V_eeg is not None else 'Att'\n",
    "    table_name = table_dir + f'{feat_name}_Acc_Train_{train_type}_Mask_{ifmask}.csv'\n",
    "    utils.save_acc_df(table_name, Subj_ID, trial_len_list, res, OVERWRITE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_discriminative_trials_LVO(Subj_ID, target_list, signal_list, compete_list, fs, para_signal, para_compete, para_target, trial_len_list, table_dir, BOOTSTRAP=True, n_components=3, nb_comp_into_account=1, OVERWRITE=False, feat_name='ObjFlow'):\n",
    "    '''\n",
    "    TASK: Determine the attended feature from the unattended feature using CCA and evaluate the performance\n",
    "\n",
    "    Inputs that need further explanation:\n",
    "    TRAIN_WITH_ATT: True if training with attended features, False if training with unattended features\n",
    "    eeg_ori_list: Original EEG data, necessary for calculating the forward model when the input eeg_multisubj_list is already hankelized (e.g., due to spatial-temporal regression)\n",
    "    dim_list_EEG: If the input eeg_multisubj_list is actually a stack of EEG and other modalities, dim_list_EEG is a list of the dimensions of each modality. E.g., [64, 4] for stacked EEG and EOG. Always put EEG at the first place.\n",
    "    dim_list_Stim: Similar to dim_list_EEG, but for the dimensions of the stimulus features.\n",
    "    saccade_multisubj_list: Saccade data. A mask will be created if saccade data is provided to exclude the time points around saccades.\n",
    "    BOOTSTRAP: True if selecting trials with given length randomly (wiith overlap), False if dividing the trials without overlap\n",
    "    V_eeg, V_Stim: If want to use pretrained filters trained from single object data, provide the filters here.\n",
    "    nb_comp_into_account: Number of components into account when calculating the accuracy\n",
    "    OVERWRITE: True if want to overwrite the existing results in the table, False otherwise\n",
    "    '''\n",
    "    res = []\n",
    "    target_list = [target[:,:,Subj_ID] for target in target_list] if np.ndim(target_list[0]) == 3 else target_list\n",
    "    signal_list = [signal[:,:,Subj_ID] for signal in signal_list] if np.ndim(signal_list[0]) == 3 else signal_list\n",
    "    compete_list = [compete[:,:,Subj_ID] for compete in compete_list] if np.ndim(compete_list[0]) == 3 else compete_list\n",
    "    DCCA = algo.DiscriminativeCCA(signal_list, compete_list, target_list, fs, para_signal, para_compete, para_target, n_components=n_components, regularization=None)\n",
    "    for trial_len in trial_len_list:\n",
    "        print('Trial length: ', trial_len)\n",
    "        corr_signal, corr_compete = DCCA.att_or_unatt_trials(trial_len=trial_len, BOOTSTRAP=BOOTSTRAP)\n",
    "        acc, _, _, _, _= utils.eval_compete(corr_signal, corr_compete, TRAIN_WITH_ATT=True, nb_comp_into_account=nb_comp_into_account)\n",
    "        res.append(acc)\n",
    "    table_name = table_dir + f'{feat_name}_Acc_Disc.csv'\n",
    "    utils.save_acc_df(table_name, Subj_ID, trial_len_list, res, OVERWRITE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_mm_trials_LVO(Subj_ID, eeg_multisubj_list, feat_match_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir, MATCHATT, dim_list_EEG=None, dim_list_Stim=None, saccade_multisubj_list=None, V_eeg=None, V_Stim=None, n_components=3, nb_comp_into_account=2, signifi_level=False, message=True, OVERWRITE=False, SINGLEOBJ=False, feat_name='ObjFlow'):\n",
    "    '''\n",
    "    TASK: Determine the matched feature from a random feature sampled from a different time point using CCA and evaluate the performance\n",
    "    '''\n",
    "    res = []\n",
    "    eeg_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_multisubj_list]\n",
    "    feat_match_list = [feat_match[:,:,Subj_ID] for feat_match in feat_match_list] if np.ndim(feat_match_list[0]) == 3 else feat_match_list\n",
    "    if saccade_multisubj_list is not None:\n",
    "        saccade_onesubj_list = [saccade[:,:,Subj_ID] for saccade in saccade_multisubj_list]\n",
    "        mask_list = utils.get_mask_list(saccade_onesubj_list, before=10, after=20)\n",
    "    else:\n",
    "        mask_list = None\n",
    "    ifmask = True if mask_list is not None else False\n",
    "    CCA = algo.CanonicalCorrelationAnalysis(eeg_onesubj_list, feat_match_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, dim_list_EEG=dim_list_EEG, dim_list_Stim=dim_list_Stim, n_components=n_components, mask_list=mask_list, signifi_level=signifi_level, message=message)\n",
    "    for trial_len in trial_len_list:\n",
    "        print('Trial length: ', trial_len)\n",
    "        corr_match_eeg, corr_mismatch_eeg = CCA.match_mismatch_LVO(trial_len=trial_len, V_eeg=V_eeg, V_Stim=V_Stim)\n",
    "        acc, _, _ = utils.eval_mm(corr_match_eeg, corr_mismatch_eeg, nb_comp_into_account)\n",
    "        res.append(acc)\n",
    "    if SINGLEOBJ:\n",
    "        table_name = table_dir + f'{feat_name}_Acc_MM_SO_Mask_{ifmask}.csv'\n",
    "    else:\n",
    "        train_type = 'SO' if V_eeg is not None else 'Att' if MATCHATT else 'Unatt'\n",
    "        table_name = table_dir + f'{feat_name}_Acc_MM_Train_{train_type}_Mask_{ifmask}.csv'\n",
    "    utils.save_acc_df(table_name, Subj_ID, trial_len_list, res, OVERWRITE)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_single_obj(Subj_ID, eeg_multisubj_list, feat_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, figure_dir, table_dir, dim_list_EEG=None, dim_list_Stim=None, saccade_multisubj_list=None, n_components=3, PLOT=False, OVERWRITE=False, feat_name='ObjFlow'):\n",
    "    '''\n",
    "    TASK: Train and test on the single-object data. Then use all single-object data to train the filters to be used in the overlaid-object data.\n",
    "    '''\n",
    "    eeg_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_multisubj_list]\n",
    "    feat_list = [feat[:,:,Subj_ID] for feat in feat_list] if np.ndim(feat_list[0]) == 3 else feat_list\n",
    "    if saccade_multisubj_list is not None:\n",
    "        saccade_onesubj_list = [saccade[:,:,Subj_ID] for saccade in saccade_multisubj_list]\n",
    "        mask_list = utils.get_mask_list(saccade_onesubj_list, before=10, after=20)\n",
    "    else:\n",
    "        mask_list = None\n",
    "    ifmask = True if mask_list is not None else False\n",
    "    CCA = algo.CanonicalCorrelationAnalysis(eeg_onesubj_list, feat_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, dim_list_EEG=dim_list_EEG, dim_list_Stim=dim_list_Stim, n_components=n_components, mask_list=mask_list)\n",
    "    corr_train_fold, corr_test_fold, sig_corr_fold, sig_corr_pool, forward_model_fold = CCA.cross_val_LVO()\n",
    "    if PLOT:\n",
    "        figure_name = f\"{figure_dir}{feat_name}_Subj_{Subj_ID+1}_Folds.png\"\n",
    "        utils.plot_spatial_resp_fold(forward_model_fold, corr_test_fold, None, sig_corr_fold, figure_name, AVG=False)\n",
    "        utils.plot_spatial_resp_fold(forward_model_fold, corr_test_fold, None, sig_corr_pool, figure_name, AVG=True)\n",
    "    table_name = table_dir + f'{feat_name}_Corr_SO_Mask_{ifmask}.csv'\n",
    "    # check if the file exists\n",
    "    if not os.path.isfile(table_name):\n",
    "        # create a pandas dataframe that contains Subj_ID, Corr_Att, Corr_Unatt, Sig_Corr\n",
    "        res_df = utils.create_corr_df(Subj_ID, sig_corr_pool, corr_train_fold, corr_test_fold)\n",
    "        res_df.rename(columns={'Att': 'Train', 'Unatt': 'Test'}, inplace=True)\n",
    "    else:\n",
    "        # read the dataframe\n",
    "        res_df = pd.read_csv(table_name, header=0, index_col=[0,1,2])\n",
    "        if not 'Subj '+str(Subj_ID+1) in res_df.index.get_level_values('Subject ID'):\n",
    "            res_add = utils.create_corr_df(Subj_ID, sig_corr_pool, corr_train_fold, corr_test_fold)\n",
    "            res_add.rename(columns={'Att': 'Train', 'Unatt': 'Test'}, inplace=True)\n",
    "            res_df = pd.concat([res_df, res_add], axis=0)\n",
    "        elif OVERWRITE:\n",
    "            res_df = res_df.drop('Subj '+str(Subj_ID+1), level='Subject ID')\n",
    "            res_add = utils.create_corr_df(Subj_ID, sig_corr_pool, corr_train_fold, corr_test_fold)\n",
    "            res_add.rename(columns={'Att': 'Train', 'Unatt': 'Test'}, inplace=True)\n",
    "            res_df = pd.concat([res_df, res_add], axis=0)\n",
    "        else:\n",
    "            print(f\"Results for Subj {Subj_ID+1} already exist in {table_name}\")\n",
    "    with open(table_name, 'w') as f:\n",
    "        res_df.to_csv(f, header=True)\n",
    "    EEG_all = np.concatenate(eeg_onesubj_list, axis=0)\n",
    "    feat_all = np.concatenate(feat_list, axis=0)\n",
    "    _, _, _, _, V_eeg_SO, V_stim_SO, _ = CCA.fit(EEG_all, feat_all)\n",
    "    return V_eeg_SO, V_stim_SO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_att_or_unatt_aug(Subj_ID, nested_data, nested_aug_data, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list=None, BOOTSTRAP=True, n_components=3, nb_comp_into_account=2, table_dir=None, OVERWRITE=False, SYNMASK=False, feat_name='ObjFlow'):\n",
    "    eeg_multisubj_list, feat_att_list, feat_unatt_list, saccade_multisubj_list = nested_data\n",
    "    eeg_multisubj_list_aug, feat_att_list_aug, _, saccade_multisubj_list_aug = nested_aug_data\n",
    "    eeg_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_multisubj_list]\n",
    "    eeg_onesubj_list_aug = [eeg[:,:,Subj_ID] for eeg in eeg_multisubj_list_aug]\n",
    "    feat_att_list = [feat_att[:,:,Subj_ID] for feat_att in feat_att_list] if np.ndim(feat_att_list[0]) == 3 else feat_att_list\n",
    "    feat_unatt_list = [feat_unatt[:,:,Subj_ID] for feat_unatt in feat_unatt_list] if np.ndim(feat_unatt_list[0]) == 3 else feat_unatt_list\n",
    "    feat_att_list_aug = [feat_att[:,:,Subj_ID] for feat_att in feat_att_list_aug] if np.ndim(feat_att_list_aug[0]) == 3 else feat_att_list_aug\n",
    "    \n",
    "    saccade_onesubj_list = [saccade[:,:,Subj_ID] for saccade in saccade_multisubj_list]\n",
    "    saccade_onesubj_list_aug = [saccade[:,:,Subj_ID] for saccade in saccade_multisubj_list_aug]\n",
    "    if SYNMASK:\n",
    "        saccade_onesubj_list = utils.shuffle_datalist(saccade_onesubj_list, 1)\n",
    "        saccade_onesubj_list_aug = utils.shuffle_datalist(saccade_onesubj_list_aug, 1)\n",
    "    mask_list = utils.get_mask_list(saccade_onesubj_list, before=10, after=30)\n",
    "    mask_list_aug = utils.get_mask_list(saccade_onesubj_list_aug, before=10, after=30)\n",
    "    data_loss = utils.data_loss_due_to_mask(mask_list+mask_list_aug, L_EEG, offset_EEG)\n",
    "\n",
    "    CCA = algo.CanonicalCorrelationAnalysis(eeg_onesubj_list, feat_att_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, n_components=n_components, mask_list=mask_list, leave_out=4)\n",
    "    corr_att_fold, corr_unatt_fold, _, sig_corr_pool = CCA.att_or_unatt_aug(eeg_onesubj_list_aug, feat_att_list_aug, mask_list_aug, feat_unatt_list, trial_len=None)\n",
    "    table_name = table_dir + f'{feat_name}_Corr_Train_Aug_Syn_{SYNMASK}.csv'\n",
    "    utils.save_corr_df(table_name, sig_corr_pool, corr_att_fold, corr_unatt_fold, Subj_ID, OVERWRITE)\n",
    "    \n",
    "    res = []\n",
    "    for trial_len in trial_len_list:\n",
    "        print('Trial length: ', trial_len)\n",
    "        corr_att_eeg, corr_unatt_eeg, _, _ = CCA.att_or_unatt_aug(eeg_onesubj_list_aug, feat_att_list_aug, mask_list_aug, feat_unatt_list, trial_len, BOOTSTRAP)\n",
    "        acc, _, _, _, _= utils.eval_compete(corr_att_eeg, corr_unatt_eeg, TRAIN_WITH_ATT=True, nb_comp_into_account=nb_comp_into_account)\n",
    "        res.append(acc)\n",
    "    table_name = table_dir + f'{feat_name}_Acc_Train_Aug_Syn_{SYNMASK}.csv'\n",
    "    utils.save_acc_df(table_name, Subj_ID, trial_len_list, res, OVERWRITE, data_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode=Compete: Discriminating between attended and unattended segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subj = ['Pilot_20', 'Pilot_21']\n",
    "new_subj_idx = [subjects.index(sub) for sub in new_subj]\n",
    "CALCU_NEW_SUBJ_ONLY = False\n",
    "Subj_Set = new_subj_idx if CALCU_NEW_SUBJ_ONLY else range(nb_subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results for either all subjects or new subjects\n",
    "for Subj_ID in Subj_Set:\n",
    "    for modal in modal_dict.keys():\n",
    "        PLOT = True if modal == 'EEG' else False\n",
    "        pipe_att_or_unatt_LVO(Subj_ID, modal_dict[modal], feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=True, PLOT=PLOT, figure_dir=figure_dirs[modal], SAVERES=True, table_dir=table_dirs[modal], OVERWRITE=True)\n",
    "        # pipe_att_or_unatt_LVO(Subj_ID, modal_dict[modal], feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=False, PLOT=PLOT, figure_dir=figure_dirs[modal], SAVERES=True, table_dir=table_dirs[modal], OVERWRITE=True)\n",
    "        pipe_compete_trials_LVO(Subj_ID, modal_dict[modal], feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dirs[modal], OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminative analysis [Not helpful]\n",
    "# para_signal = [L_Stim, offset_Stim]\n",
    "# para_compete = [L_Stim, offset_Stim]\n",
    "# para_target = [L_EEG, offset_EEG]\n",
    "# for Subj_ID in Subj_Set:\n",
    "#     for modal in modal_dict.keys():\n",
    "#         pipe_discriminative_trials_LVO(Subj_ID, modal_dict[modal], feat_att_list, feat_unatt_list, fs, para_signal, para_compete, para_target, trial_len_list, table_dir=table_dirs[modal], BOOTSTRAP=True, n_components=3, nb_comp_into_account=1, OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If contains single object dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results for either all subjects or new subjects\n",
    "if SINGLEOBJ:\n",
    "    for Subj_ID in Subj_Set:\n",
    "        # V_eeg_SO, V_stim_SO = pipe_single_obj(Subj_ID, modal_dict_SO['EEG'], feat_list_SO, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, figure_dirs['EEG'], table_dirs['EEG'], saccade_multisubj_list=None, n_components=3, PLOT=True, OVERWRITE=True)\n",
    "        # pipe_att_or_unatt_LVO(Subj_ID, modal_dict['EEG'], feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=True, PLOT=True, figure_dir=figure_dirs['EEG'], SAVERES=True, table_dir=table_dirs['EEG'], V_eeg=V_eeg_SO, V_Stim=V_stim_SO, OVERWRITE=True)\n",
    "        # pipe_compete_trials_LVO(Subj_ID, modal_dict['EEG'], feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dirs['EEG'], V_eeg=V_eeg_SO, V_Stim=V_stim_SO, OVERWRITE=True)\n",
    "        for modal in modal_dict.keys():\n",
    "            pipe_mm_trials_LVO(Subj_ID, modal_dict_SO[modal], feat_list_SO, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dirs[modal], MATCHATT=True, OVERWRITE=True, SINGLEOBJ=SINGLEOBJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If remove saccades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_saccade(nested_data, nested_aug_data, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list=None, BOOTSTRAP=True, n_components=3, nb_comp_into_account=2, table_dir=None, OVERWRITE=False, SYNMASK=False, feat_name='ObjFlow'):\n",
    "    eeg_multisubj_list, feat_att_list, feat_unatt_list, saccade_multisubj_list = nested_data\n",
    "    eeg_multisubj_list_aug, feat_att_list_aug, _, saccade_multisubj_list_aug = nested_aug_data\n",
    "    nb_subj = eeg_multisubj_list[0].shape[2]\n",
    "    mask_list = None\n",
    "    mask_list_aug = None\n",
    "    data_loss = []\n",
    "    for Subj_ID in range(nb_subj):\n",
    "        saccade_onesubj_list = [saccade[:,:,Subj_ID] for saccade in saccade_multisubj_list]\n",
    "        saccade_onesubj_list_aug = [saccade[:,:,Subj_ID] for saccade in saccade_multisubj_list_aug]\n",
    "        if SYNMASK:\n",
    "            saccade_onesubj_list = utils.shuffle_datalist(saccade_onesubj_list, 1)\n",
    "            saccade_onesubj_list_aug = utils.shuffle_datalist(saccade_onesubj_list_aug, 1)\n",
    "        mask_onesubj_list = utils.get_mask_list(saccade_onesubj_list, before=10, after=30, ThreeD=True)\n",
    "        mask_onesubj_list_aug = utils.get_mask_list(saccade_onesubj_list_aug, before=10, after=30, ThreeD=True)\n",
    "        if mask_list is None:\n",
    "            mask_list = mask_onesubj_list\n",
    "            mask_list_aug = mask_onesubj_list_aug\n",
    "        else:\n",
    "            mask_list = [np.concatenate((mask_prev_subjs, mask), axis=2) for mask_prev_subjs, mask in zip(mask_list, mask_onesubj_list)]\n",
    "            mask_list_aug = [np.concatenate((mask_prev_subjs, mask), axis=2) for mask_prev_subjs, mask in zip(mask_list_aug, mask_onesubj_list_aug)]\n",
    "        data_loss_onesubj = utils.data_loss_due_to_mask(mask_onesubj_list+mask_onesubj_list_aug, L_EEG, offset_EEG)\n",
    "        data_loss.append(data_loss_onesubj)\n",
    "\n",
    "    CCA = algo.CanonicalCorrelationAnalysis(eeg_multisubj_list, feat_att_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, n_components=n_components, mask_list=mask_list, leave_out=7)\n",
    "    res = {Subj_ID: [] for Subj_ID in range(nb_subj)}\n",
    "    table_name = table_dir + f'{feat_name}_Acc_Train_Aug_Multisubj_Syn_{SYNMASK}.csv'\n",
    "    for trial_len in trial_len_list:\n",
    "        print('Trial length: ', trial_len)\n",
    "        corr_att_eeg, corr_unatt_eeg = CCA.att_or_unatt_aug_multisubj(eeg_multisubj_list_aug, feat_att_list_aug, mask_list_aug, feat_unatt_list, trial_len, BOOTSTRAP)\n",
    "        for Subj_ID in range(nb_subj):\n",
    "            acc, _, _, _, _= utils.eval_compete(corr_att_eeg[Subj_ID], corr_unatt_eeg[Subj_ID], TRAIN_WITH_ATT=True, nb_comp_into_account=nb_comp_into_account)\n",
    "            res[Subj_ID].append(acc)\n",
    "    for Subj_ID in range(nb_subj):\n",
    "        utils.save_acc_df(table_name, Subj_ID, trial_len_list, res[Subj_ID], OVERWRITE, data_loss[Subj_ID])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_data = [modal_dict['EEG'], feat_att_list, feat_unatt_list, modal_dict['SACC']]\n",
    "nested_aug_data = [modal_dict_SO['EEG'], feat_list_SO, None, modal_dict_SO['SACC']]\n",
    "pipe_saccade(nested_data, nested_aug_data, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir=table_dirs['EEG'], OVERWRITE=True, SYNMASK=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(1, 11):\n",
    "    name = f'Run{run}-ObjFlow'\n",
    "    nested_data = [modal_dict['EEG'], feat_att_list, feat_unatt_list, modal_dict['SACC']]\n",
    "    nested_aug_data = [modal_dict_SO['EEG'], feat_list_SO, None, modal_dict_SO['SACC']]\n",
    "    pipe_saccade(nested_data, nested_aug_data, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir=table_dirs['EEG'], OVERWRITE=True, SYNMASK=True, feat_name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If use a subset of EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "montage = mne.channels.make_standard_montage('biosemi64')\n",
    "# vis_collection = ['O2', 'Oz', 'O1', 'PO4', 'POz', 'PO3', 'P4', 'P2', 'Pz', 'P1', 'P3', 'CP2', 'CP1', 'C4', 'Cz', 'C3']\n",
    "vis_collection = ['O2', 'Oz', 'O1', 'PO8', 'PO4', 'POz', 'PO3', 'PO7']\n",
    "vis_collection_indices = [montage.ch_names.index(ch) for ch in vis_collection]\n",
    "data = modal_dict['EEG']\n",
    "eeg_subset = [eeg[:,vis_collection_indices,:] for eeg in data]\n",
    "for Subj_ID in Subj_Set:\n",
    "    pipe_att_or_unatt_LVO(Subj_ID, eeg_subset, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=True, SAVERES=True, table_dir=table_dirs['EEG'], OVERWRITE=True, feat_name='Subset-OF')\n",
    "    pipe_compete_trials_LVO(Subj_ID, eeg_subset, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dirs['EEG'], OVERWRITE=True, feat_name='Subset-OF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode=Match-Mismatch: Discriminating between match and mismatch segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results for either all subjects or new subjects\n",
    "for Subj_ID in Subj_Set:\n",
    "    for modal in modal_dict.keys():\n",
    "        pipe_mm_trials_LVO(Subj_ID, modal_dict[modal], feat_att_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dirs[modal], MATCHATT=True, OVERWRITE=True)\n",
    "        # pipe_mm_trials_LVO(Subj_ID, modal_dict[modal], feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dirs[modal], MATCHATT=False, OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making use of multi-modal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking different modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_dict = {'EEG+EOG': utils.stack_modal([modal_dict['EEG'], modal_dict['EOG']]), \n",
    "             'EEG+GAZE_V': utils.stack_modal([modal_dict['EEG'], modal_dict['GAZE_V']]), \n",
    "             'EOG+GAZE_V': utils.stack_modal([modal_dict['EOG'], modal_dict['GAZE_V']]), \n",
    "             'EEG+EOG+GAZE_V': utils.stack_modal([modal_dict['EEG'], modal_dict['EOG'], modal_dict['GAZE_V']])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comb, modal in comb_dict.items():\n",
    "    table_path = f'tables/{PATTERN}/{comb}/'\n",
    "    utils.create_dir(table_path, CLEAR)\n",
    "    for Subj_ID in Subj_Set:\n",
    "        pipe_att_or_unatt_LVO(Subj_ID, modal[0], feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, dim_list_EEG=modal[1], TRAIN_WITH_ATT=True, SAVERES=True, table_dir=table_path, OVERWRITE=True)\n",
    "        pipe_compete_trials_LVO(Subj_ID, modal[0], feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_path, dim_list_EEG=modal[1], OVERWRITE=True, nb_comp_into_account=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comb, modal in comb_dict.items():\n",
    "    table_path = f'tables/{PATTERN}/{comb}/'\n",
    "    utils.create_dir(table_path, CLEAR)\n",
    "    for Subj_ID in Subj_Set:\n",
    "        pipe_mm_trials_LVO(Subj_ID, modal[0], feat_att_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_path, MATCHATT=True, dim_list_EEG=modal[1], OVERWRITE=True, nb_comp_into_account=3)\n",
    "        # pipe_mm_trials_LVO(Subj_ID, modal[0], feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_path, MATCHATT=False, dim_list_EEG=modal[1], OVERWRITE=True, nb_comp_into_account=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCCA with multi-modal data [Not as good as the previous one]\n",
    "Potential problem: the correlation between, e.g., EEG and GAZE_V, dominates the ISC when the feature is less informative. \n",
    "Therefore the ISCs under attended and unattended conditions are not well separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_att_or_unatt_gcca(Subj_ID, nested_datalist, fs, L_list, offset_list, n_components=4, nb_comp_into_account=2, trial_len_list=[15,30,45,60], table_dir=None, OVERWRITE=False, feat_name='ObjFlow'):\n",
    "    '''\n",
    "    TASK: Perform GCCA analysis on given modalities (including stimulus features); Attended features and unattended features are discriminated based on ISC.\n",
    "    nested_datalist: A list of lists of data for each modality. The last modality is the attended stimulus feature. E.g., [EEG_list, EOG_list, feat_att_list, feat_unatt_list]\n",
    "    The last two lists are the attended and unattended stimulus features, respectively.\n",
    "    '''\n",
    "    data_mm_list = [[data[:,:,Subj_ID] for data in data_list] for data_list in nested_datalist[:-2]]\n",
    "    feat_att_list, feat_unatt_list = nested_datalist[-2], nested_datalist[-1]\n",
    "    feat_att_list = [feat_att[:,:,Subj_ID] for feat_att in feat_att_list] if np.ndim(feat_att_list[0]) == 3 else feat_att_list\n",
    "    feat_unatt_list = [feat_unatt[:,:,Subj_ID] for feat_unatt in feat_unatt_list] if np.ndim(feat_unatt_list[0]) == 3 else feat_unatt_list\n",
    "    GCCA_MM = algo.GeneralizedCCA_MultiMod(data_mm_list+[feat_att_list, feat_unatt_list], fs, L_list, offset_list, leave_out=2, n_components=n_components)\n",
    "    res = []\n",
    "    for trial_len in trial_len_list:\n",
    "        print('Trial length: ', trial_len)\n",
    "        isc_att, isc_unatt = GCCA_MM.att_or_unatt_LVO_trials(trial_len)\n",
    "        acc, _, _, _, _= utils.eval_compete(isc_att, isc_unatt, TRAIN_WITH_ATT=True, nb_comp_into_account=nb_comp_into_account)\n",
    "        res.append(acc)\n",
    "    table_name = table_dir + f'{feat_name}_Acc_MM.csv'\n",
    "    utils.save_acc_df(table_name, Subj_ID, trial_len_list, res, OVERWRITE)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subj_ID = 0\n",
    "nested_datalist = [modal_dict['EEG'], modal_dict['GAZE_V'], feat_att_list, feat_unatt_list]\n",
    "L_list = [L_EEG, L_EEG, L_Stim, L_Stim]\n",
    "offset_list = [offset_EEG, offset_EEG, offset_Stim, offset_Stim]\n",
    "# nested_datalist = [modal_dict['EEG'], feat_att_list, feat_unatt_list]\n",
    "# L_list = [L_EEG, L_Stim, L_Stim]\n",
    "# offset_list = [offset_EEG, offset_Stim, offset_Stim]\n",
    "pipe_att_or_unatt_gcca(Subj_ID, nested_datalist, fs, L_list, offset_list, nb_comp_into_account=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressing out other modalities from EEG (Partial CCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_out_confounds(data_list, feat_att_list, feat_unatt_list, confound_list, L_data, L_Stim, offset_data, offset_Stim):\n",
    "    '''\n",
    "    Regressing confound (modality to be controlled) out of the data and features\n",
    "    '''\n",
    "    data_reg = utils.further_regress_out_list(data_list, confound_list, L_data, L_data, offset_data, offset_data)\n",
    "    feat_att_reg = utils.further_regress_out_list(feat_att_list, confound_list, L_Stim, L_data, offset_Stim, offset_data)\n",
    "    feat_unatt_reg = utils.further_regress_out_list(feat_unatt_list, confound_list, L_Stim, L_data, offset_Stim, offset_data)\n",
    "    return (data_reg, feat_att_reg, feat_unatt_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dict = {'EEG-EOG': regress_out_confounds(modal_dict['EEG'], feat_att_list, feat_unatt_list, modal_dict['EOG'], L_EEG, L_Stim, offset_EEG, offset_Stim),\n",
    "             'EEG-GAZE_V': regress_out_confounds(modal_dict['EEG'], feat_att_list, feat_unatt_list, modal_dict['GAZE_V'], L_EEG, L_Stim, offset_EEG, offset_Stim),\n",
    "             'GAZE_V-EEG': regress_out_confounds(modal_dict['GAZE_V'], feat_att_list, feat_unatt_list, modal_dict['EEG'], L_EEG, L_Stim, offset_EEG, offset_Stim),\n",
    "             'EEG-EOG&GAZE_V': regress_out_confounds(modal_dict['EEG'], feat_att_list, feat_unatt_list, comb_dict['EOG+GAZE_V'][0], L_EEG, L_Stim, offset_EEG, offset_Stim),\n",
    "             'EOG-GAZE_V': regress_out_confounds(modal_dict['EOG'], feat_att_list, feat_unatt_list, modal_dict['GAZE_V'], L_EEG, L_Stim, offset_EEG, offset_Stim),\n",
    "             'GAZE_V-EOG': regress_out_confounds(modal_dict['GAZE_V'], feat_att_list, feat_unatt_list, modal_dict['EOG'], L_EEG, L_Stim, offset_EEG, offset_Stim)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg, modal in reg_dict.items():\n",
    "    table_path = f'tables/{PATTERN}/{reg}/'\n",
    "    utils.create_dir(table_path, CLEAR=False)\n",
    "    PLOT = (reg.split('-')[0] == 'EEG')\n",
    "    if PLOT:\n",
    "        figure_path = f'figures/{PATTERN}/{reg}/'\n",
    "        utils.create_dir(figure_path, CLEAR=False)\n",
    "    else:\n",
    "        figure_path = None\n",
    "    for Subj_ID in Subj_Set:\n",
    "        pipe_att_or_unatt_LVO(Subj_ID, modal[0], modal[1], modal[2], fs, L_EEG=1, L_Stim=1, offset_EEG=0, offset_Stim=0, TRAIN_WITH_ATT=True, eeg_ori_list=modal_dict['EEG'], PLOT=PLOT, figure_dir=figure_path, SAVERES=True, table_dir=table_path, OVERWRITE=True)\n",
    "        pipe_compete_trials_LVO(Subj_ID, modal[0], modal[1], modal[2], fs, L_EEG=1, L_Stim=1, offset_EEG=0, offset_Stim=0, trial_len_list=trial_len_list, table_dir=table_path, OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the results for either all subjects or new subjects\n",
    "for Subj_ID in Subj_Set:\n",
    "    for reg, modal in reg_dict.items():\n",
    "        table_path = f'tables/{PATTERN}/{reg}/'\n",
    "        pipe_mm_trials_LVO(Subj_ID, modal[0], modal[1], fs, 1, 1, 0, 0, trial_len_list, table_path, MATCHATT=True, OVERWRITE=True)\n",
    "        # pipe_mm_trials_LVO(Subj_ID, modal[0], modal[2], fs, 1, 1, 0, 0, trial_len_list, table_path, MATCHATT=False, OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_GCCA(nested_datalist, fs, L_list, offset_list, mod_name_list, W_list, nested_dimlist, figure_dir, table_dir, n_components=10, SINGLEOBJ=False, OVERWRITE=False, FM_ORG=None):\n",
    "    prefix = 'SO_' if SINGLEOBJ else 'OL_'\n",
    "    table_name = table_dir + f'{prefix}Single_Mod.csv' if W_list[0] is None else table_dir + f'Single_Mod_Pretrain_on_SO.csv'\n",
    "    for datalist, L, offset, mod_name, W_data, dim_list in zip(nested_datalist, L_list, offset_list, mod_name_list, W_list, nested_dimlist):\n",
    "        GCCA = algo.GeneralizedCCA(datalist, fs, L=L, offset=offset, dim_list=dim_list, n_components=n_components, signifi_level=True)\n",
    "        _, corr_test_fold, _, cov_test_fold, _, _, sig_corr_fold, sig_corr_pool, forward_model_fold = GCCA.cross_val_LVO(W_eeg=W_data)\n",
    "        if FM_ORG is not None:\n",
    "            forward_model_fold = [utils.F_organize(forward_model, FM_ORG[0], FM_ORG[1]) for forward_model in forward_model_fold]\n",
    "        if forward_model_fold[0].shape[0] == 64:\n",
    "            figure_name = figure_dir + f\"{prefix}{mod_name}_Folds.png\" if W_data is None else figure_dir + f\"{prefix}{mod_name}_Pretrain_on_SO_Folds.png\"\n",
    "            utils.plot_spatial_resp_fold(forward_model_fold, corr_test_fold, None, sig_corr_fold, figure_name, AVG=False)\n",
    "            utils.plot_spatial_resp_fold(forward_model_fold, corr_test_fold, None, sig_corr_pool, figure_name, AVG=True)\n",
    "        # check if the file exists\n",
    "        if not os.path.isfile(table_name):\n",
    "            # create a pandas dataframe that contains Subj_ID, Corr_Att, Corr_Unatt, Sig_Corr\n",
    "            res_df = utils.create_ISC_df(corr_test_fold, cov_test_fold, sig_corr_pool, mod_name)\n",
    "        else:\n",
    "            # read the dataframe\n",
    "            res_df = pd.read_csv(table_name, header=0, index_col=[0,1,2])\n",
    "            if not mod_name in res_df.index.get_level_values('Modality'):\n",
    "                res_add = utils.create_ISC_df(corr_test_fold, cov_test_fold, sig_corr_pool, mod_name)\n",
    "                res_df = pd.concat([res_df, res_add], axis=0)\n",
    "            elif OVERWRITE:\n",
    "                res_df = res_df.drop(mod_name, level='Modality')\n",
    "                res_add = utils.create_ISC_df(corr_test_fold, cov_test_fold, sig_corr_pool, mod_name)\n",
    "                res_df = pd.concat([res_df, res_add], axis=0)\n",
    "            else:\n",
    "                print(f\"Results for {mod_name} already exist in {table_name}\")\n",
    "        with open(table_name, 'w') as f:\n",
    "            res_df.to_csv(f, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCCA_table_path = f'tables/{PATTERN}/GCCA/'\n",
    "GCCA_figure_path = f'figures/{PATTERN}/GCCA/'\n",
    "utils.create_dir(GCCA_table_path, CLEAR=False)\n",
    "utils.create_dir(GCCA_figure_path, CLEAR=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-object dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_datalist = list(modal_dict_SO.values()) \n",
    "mod_name_list = list(modal_dict_SO.keys()) \n",
    "L_list = [5]*len(nested_datalist)\n",
    "offset_list = [2]*len(nested_datalist)\n",
    "W_list = [None]*len(nested_datalist)\n",
    "nested_dimlist = [None]*len(nested_datalist)\n",
    "pipe_GCCA(nested_datalist, fs, L_list, offset_list, mod_name_list, W_list, nested_dimlist, GCCA_figure_path, GCCA_table_path, SINGLEOBJ=True, OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_dict_SO = {'EEG+EOG': utils.stack_modal([modal_dict_SO['EEG'], modal_dict_SO['EOG']]), \n",
    "             'EEG+GAZE_V': utils.stack_modal([modal_dict_SO['EEG'], modal_dict_SO['GAZE_V']]), \n",
    "             'EOG+GAZE_V': utils.stack_modal([modal_dict_SO['EOG'], modal_dict_SO['GAZE_V']]), \n",
    "             'EEG+EOG+GAZE_V': utils.stack_modal([modal_dict_SO['EEG'], modal_dict_SO['EOG'], modal_dict_SO['GAZE_V']])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_gcca_dict_SO = {'EEG-EOG': regress_out_confounds(modal_dict_SO['EEG'], feat_list_SO, feat_list_SO, modal_dict_SO['EOG'], L_data=5, L_Stim=1, offset_data=2, offset_Stim=0),\n",
    "             'EEG-GAZE_V': regress_out_confounds(modal_dict_SO['EEG'], feat_list_SO, feat_list_SO, modal_dict_SO['GAZE_V'], L_data=5, L_Stim=1, offset_data=2, offset_Stim=0),\n",
    "             'EEG-EOG&GAZE_V': regress_out_confounds(modal_dict_SO['EEG'], feat_list_SO, feat_list_SO, comb_dict_SO['EOG+GAZE_V'][0], L_data=5, L_Stim=1, offset_data=2, offset_Stim=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_datalist = [modal[0] for modal in reg_gcca_dict_SO.values()] \n",
    "mod_name_list = list(reg_gcca_dict_SO.keys()) \n",
    "L_list = [1]*len(nested_datalist)\n",
    "offset_list = [0]*len(nested_datalist)\n",
    "W_list = [None]*len(nested_datalist)\n",
    "nested_dimlist = [None]*len(nested_datalist)\n",
    "pipe_GCCA(nested_datalist, fs, L_list, offset_list, mod_name_list, W_list, nested_dimlist, GCCA_figure_path, GCCA_table_path, SINGLEOBJ=True, OVERWRITE=True, FM_ORG=[5 ,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlaid-object dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_datalist = list(modal_dict.values())\n",
    "mod_name_list = list(modal_dict.keys()) \n",
    "L_list = [5]*len(nested_datalist)\n",
    "offset_list = [2]*len(nested_datalist)\n",
    "W_list = [None]*len(nested_datalist)\n",
    "nested_dimlist = [None]*len(nested_datalist)\n",
    "pipe_GCCA(nested_datalist, fs, L_list, offset_list, mod_name_list, W_list, nested_dimlist, GCCA_figure_path, GCCA_table_path, SINGLEOBJ=False, OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_gcca_dict = {'EEG-EOG': regress_out_confounds(modal_dict['EEG'], feat_att_list, feat_unatt_list, modal_dict['EOG'], L_data=5, L_Stim=1, offset_data=2, offset_Stim=0),\n",
    "             'EEG-GAZE_V': regress_out_confounds(modal_dict['EEG'], feat_att_list, feat_unatt_list, modal_dict['GAZE_V'], L_data=5, L_Stim=1, offset_data=2, offset_Stim=0),\n",
    "             'EEG-EOG&GAZE_V': regress_out_confounds(modal_dict['EEG'], feat_att_list, feat_unatt_list, comb_dict['EOG+GAZE_V'][0], L_data=5, L_Stim=1, offset_data=2, offset_Stim=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_datalist = [modal[0] for modal in reg_gcca_dict.values()] \n",
    "mod_name_list = list(reg_gcca_dict.keys()) \n",
    "L_list = [1]*len(nested_datalist)\n",
    "offset_list = [0]*len(nested_datalist)\n",
    "W_list = [None]*len(nested_datalist)\n",
    "nested_dimlist = [None]*len(nested_datalist)\n",
    "pipe_GCCA(nested_datalist, fs, L_list, offset_list, mod_name_list, W_list, nested_dimlist, GCCA_figure_path, GCCA_table_path, SINGLEOBJ=False, OVERWRITE=True, FM_ORG=[5 ,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCCA as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_percentage(corr_att, corr_unatt, sim, figure_dir, Subj_ID, nb_comp_into_account=2, name_prepend='Test_'):\n",
    "    # Remove rows where any value is NaN (because the trial length is too long for some folds/subjects)\n",
    "    idx_not_nan = ~np.isnan(corr_att).any(axis=1)\n",
    "    corr_att = corr_att[idx_not_nan,:]\n",
    "    corr_unatt = corr_unatt[idx_not_nan,:]\n",
    "    corr_att = np.array([np.sort(row)[::-1] for row in corr_att])\n",
    "    corr_unatt = np.array([np.sort(row)[::-1] for row in corr_unatt])\n",
    "    stat_att = np.sum(corr_att[:,:nb_comp_into_account], axis=1)\n",
    "    stat_unatt = np.sum(corr_unatt[:,:nb_comp_into_account], axis=1)\n",
    "    label = stat_att > stat_unatt\n",
    "    rank_sim = np.argsort(sim)\n",
    "    label = label[rank_sim]\n",
    "    sim = sim[rank_sim]\n",
    "    # Calculate cumulative sum of the label\n",
    "    cum_label = np.sum(label) - np.cumsum(label)\n",
    "    acc_step = cum_label[:-1] / (len(label) - np.arange(1, len(label)))\n",
    "    \n",
    "    plt.close('all')\n",
    "    # Create two subplots with a shared x-axis\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "    # Plot the violin plot of sim on the first subplot\n",
    "    sns.violinplot(x=sim, hue=label, ax=ax1, fill=False, split=True)\n",
    "    ax1.set_xlabel('Similarity')\n",
    "    ax1.tick_params('y', colors='r')\n",
    "    ax1.set_title('Similarity distributions when decoding correctly and incorrectly')\n",
    "    # Plot the accuracy on the second subplot\n",
    "    ax2.plot(sim[:-1], acc_step)\n",
    "    ax2.set_ylabel('Acc')\n",
    "    ax2.tick_params('y')\n",
    "    ax2.set_xlabel('Similarity Threshold')\n",
    "    ax2.set_title('Accuracy when considering the trials with similarity above a threshold')\n",
    "\n",
    "    figure_name = figure_dir + f'{name_prepend}Acc_Percentage_Subj_{Subj_ID+1}.png'\n",
    "    plt.savefig(figure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_GCCA_preprocessed(eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, para_gcca, para_cca_eeg, para_cca_stim, table_dir, figure_dir=None, n_components_GCCA=192, n_components_CCA=3, nb_comp_kept_grid=range(16, 200, 16), nb_comp_into_account=2, feat_name='ObjFlow', trial_len=30, OVERWRITE=False):\n",
    "    nb_subj = eeg_multisubj_list[0].shape[2]\n",
    "    GCCA_CCA = algo.GCCAPreprocessedCCA(0, eeg_multisubj_list, feat_att_list, fs, para_gcca, para_cca_eeg, para_cca_stim, leave_out=2, n_components_GCCA=n_components_GCCA, n_components_CCA=n_components_CCA)\n",
    "    nb_comp_kept = GCCA_CCA.search_para(nb_comp_kept_grid)\n",
    "    print(f'Number of components kept after GCCA: {nb_comp_kept}')\n",
    "    acc_test_list = []\n",
    "    sim_test_list = []\n",
    "    for Subj_ID in range(nb_subj):\n",
    "        GCCA_CCA.switch_subj(Subj_ID)\n",
    "        corr_att_eeg_train, corr_att_eeg_test, corr_unatt_eeg_train, corr_unatt_eeg_test, sim_train, sim_test = GCCA_CCA.att_or_unatt_trials(feat_unatt_list, trial_len=trial_len)\n",
    "        if figure_dir is not None:\n",
    "            plot_accuracy_percentage(corr_att_eeg_train, corr_unatt_eeg_train, np.sum(sim_train, axis=1), figure_dir, Subj_ID, nb_comp_into_account=nb_comp_into_account, name_prepend='Train_')\n",
    "            plot_accuracy_percentage(corr_att_eeg_test, corr_unatt_eeg_test, np.sum(sim_test, axis=1), figure_dir, Subj_ID, nb_comp_into_account=nb_comp_into_account)\n",
    "        acc_test, _, _, _, _= utils.eval_compete(corr_att_eeg_test, corr_unatt_eeg_test, TRAIN_WITH_ATT=True, nb_comp_into_account=nb_comp_into_account)\n",
    "        acc_test_list.append(acc_test)\n",
    "        sim_test_list.append(np.median(np.sum(sim_test, axis=1)))\n",
    "    \n",
    "    # Convert the nested lists to NumPy arrays\n",
    "    data_array = np.c_[np.array(acc_test_list), np.array(sim_test_list)]\n",
    "    table_name = table_dir + f'{feat_name}_GCCA_Acc_len_{trial_len}.csv'\n",
    "    if not os.path.isfile(table_name) or OVERWRITE:\n",
    "        data_df = pd.DataFrame(data_array, index=['Subj '+str(i) for i in range(1, nb_subj+1)], columns=['Acc', 'Sim'])\n",
    "        data_df.index.name = 'Subject ID'\n",
    "        data_df.to_csv(table_name, header=True)\n",
    "    else:\n",
    "        print(f\"Results already exist in {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_gcca = [5, 2]\n",
    "para_cca_eeg = [1, 0]\n",
    "para_cca_stim = [L_Stim, offset_Stim]\n",
    "pipe_GCCA_preprocessed(modal_dict['EEG'], feat_att_list, feat_unatt_list, fs, para_gcca, para_cca_eeg, para_cca_stim, table_dir=table_dirs['EEG'], figure_dir=figure_dirs['EEG'], OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_gcca = [5, 2]\n",
    "para_cca_eeg = [1, 0]\n",
    "para_cca_stim = [L_Stim, offset_Stim]\n",
    "pipe_GCCA_preprocessed(modal_dict['GAZE_V'], feat_att_list, feat_unatt_list, fs, para_gcca, para_cca_eeg, para_cca_stim, n_components_GCCA=5, n_components_CCA=2, nb_comp_kept_grid=range(2,4), table_dir=table_dirs['GAZE_V'], figure_dir=figure_dirs['GAZE_V'], OVERWRITE=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
