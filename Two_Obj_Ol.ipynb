{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import algo\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import binomtest, binom\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(feats_path_folder, video_id, len_seg, offset=None, smooth=True):\n",
    "    with open(feats_path_folder + video_id + '_mask.pkl', 'rb') as f:\n",
    "        feats = pickle.load(f)\n",
    "    feats = np.concatenate(tuple(feats), axis=0)\n",
    "    feats = utils.clean_features(feats, smooth=smooth)\n",
    "    if offset is not None:\n",
    "        end_idx = min(offset + len_seg, feats.shape[0])\n",
    "        start_idx = end_idx - len_seg\n",
    "        feats = feats[start_idx:end_idx, :]\n",
    "    else:\n",
    "        feats = feats[:len_seg, :]\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaze(gaze_path, len_seg, offset=None):\n",
    "    gaze = np.load(gaze_path, allow_pickle=True)\n",
    "    # interpolate missing values\n",
    "    gaze = np.array([np.nan if x is None else x for x in gaze])\n",
    "    gaze_clean = utils.clean_features(gaze.astype(np.float64), smooth=False)\n",
    "    if offset is not None:\n",
    "        end_idx = min(offset + len_seg, gaze_clean.shape[0])\n",
    "        start_idx = end_idx - len_seg\n",
    "        gaze_clean = gaze_clean[start_idx:end_idx, :]\n",
    "    else:\n",
    "        gaze_clean = gaze_clean[:len_seg, :]\n",
    "    return gaze_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eeg_eog(eeg_path, fsStim, bads, expdim=True):\n",
    "    eeg_prepro, fs, _ = utils.preprocessing(eeg_path, HP_cutoff = 0.5, AC_freqs=50, band=None, resamp_freqs=fsStim, bads=bads, eog=True, regression=True, normalize=True)\n",
    "    eeg_channel_indices = mne.pick_types(eeg_prepro.info, eeg=True)\n",
    "    eog_channel_indices = mne.pick_types(eeg_prepro.info, eog=True)\n",
    "    eeg_downsampled, _ = eeg_prepro[eeg_channel_indices]\n",
    "    eog_downsampled, _ = eeg_prepro[eog_channel_indices]\n",
    "    if expdim:\n",
    "        eeg_downsampled = np.expand_dims(eeg_downsampled.T, axis=2)\n",
    "        eog_downsampled = np.expand_dims(eog_downsampled.T, axis=2)\n",
    "    return eeg_downsampled, eog_downsampled, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_per_subj(eeg_folder, fsStim, bads, singleobj, feats_path_folder=None, expdim=True):\n",
    "    eeg_files_all = [file for file in os.listdir(eeg_folder) if file.endswith('.set')]\n",
    "    if singleobj:\n",
    "        files = [file for file in eeg_files_all if len(file.split('_')) == 1]\n",
    "    else:\n",
    "        files = [file for file in eeg_files_all if len(file.split('_')) == 3]\n",
    "    files.sort()\n",
    "    nb_files = len(files)\n",
    "    eeg_list = []\n",
    "    eog_list = []\n",
    "    len_seg_list = []\n",
    "    gaze_list = []\n",
    "    for file in files:\n",
    "        eeg_downsampled, eog_downsampled, fs = get_eeg_eog(eeg_folder + file, fsStim, bads, expdim)\n",
    "        eeg_list.append(eeg_downsampled)\n",
    "        eog_list.append(eog_downsampled)\n",
    "        len_seg_list.append(eeg_downsampled.shape[0])\n",
    "        id_att = file[:-4].split('_')[-1]\n",
    "        gaze_file = [file for file in os.listdir(eeg_folder) if file.endswith('.npy') and file.split('_')[-2]==id_att]\n",
    "        if len(gaze_file) == 1:\n",
    "            offset = 122 * fsStim if not singleobj else None\n",
    "            gaze = get_gaze(eeg_folder + gaze_file[0], len_seg_list[-1], offset)\n",
    "            gaze = np.expand_dims(gaze, axis=2)\n",
    "        else:\n",
    "            gaze = np.zeros((len_seg_list[-1], 2, 1))\n",
    "        gaze_list.append(gaze)\n",
    "    if feats_path_folder is not None:\n",
    "        feat_att_list = []\n",
    "        feat_unatt_list = []\n",
    "        for i in range(len(files)):\n",
    "            file = files[i]\n",
    "            len_seg = len_seg_list[i]\n",
    "            name = file[:-4]\n",
    "            id_att = name.split('_')[-1]\n",
    "            if singleobj:\n",
    "                feats_att = get_features(feats_path_folder, id_att, len_seg, offset=None, smooth=True)\n",
    "                feats_unatt = None\n",
    "            else:\n",
    "                offset = 122 * fsStim\n",
    "                ids = set(name.split('_'))\n",
    "                ids.remove(id_att)\n",
    "                id_unatt = ids.pop()\n",
    "                feats_att = get_features(feats_path_folder, id_att, len_seg, offset, smooth=True)\n",
    "                feats_unatt = get_features(feats_path_folder, id_unatt, len_seg, offset, smooth=True)\n",
    "            feat_att_list.append(feats_att)\n",
    "            feat_unatt_list.append(feats_unatt)\n",
    "    else:\n",
    "        feat_att_list = None\n",
    "        feat_unatt_list = None\n",
    "    return eeg_list, eog_list, feat_att_list, feat_unatt_list, gaze_list, fs, nb_files, len_seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_multi_subj(subj_path, fsStim, bads, singleobj, feats_path_folder, SAVE=True):\n",
    "    PATTERN = subj_path[0].split('/')[-3]\n",
    "    data_path = 'data/' + PATTERN + '/'\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    nb_subj = len(subj_path)\n",
    "    eeg_multisubj_list, eog_multisubj_list, feat_att_list, feat_unatt_list, gaze_multisubj_list, fs, nb_files, len_seg_list = data_per_subj(subj_path[0], fsStim, bads[0], singleobj, feats_path_folder)\n",
    "    for n in range(1,nb_subj):\n",
    "        eeg_list, eog_list, _, _, gaze_list, _, nb_files_sub, _ = data_per_subj(subj_path[n], fsStim, bads[n], singleobj, feats_path_folder=None)\n",
    "        assert nb_files == nb_files_sub\n",
    "        eeg_multisubj_list = [np.concatenate((eeg_multisubj_list[i], eeg_list[i]), axis=2) for i in range(nb_files)]\n",
    "        eog_multisubj_list = [np.concatenate((eog_multisubj_list[i], eog_list[i]), axis=2) for i in range(nb_files)]\n",
    "        gaze_multisubj_list = [np.concatenate((gaze_multisubj_list[i], gaze_list[i]), axis=2) for i in range(nb_files)]\n",
    "    if SAVE:\n",
    "        # save all data (eeg_multisubj_list, eog_multisubj_list, feat_att_list, feat_unatt_list, fs, nb_files) into a single file\n",
    "        data = {'eeg_multisubj_list': eeg_multisubj_list, 'eog_multisubj_list': eog_multisubj_list, 'feat_att_list': feat_att_list, 'feat_unatt_list': feat_unatt_list, 'gaze_multisubj_list': gaze_multisubj_list, 'fs': fs, 'len_seg_list': len_seg_list}\n",
    "        file_name = 'data_singleobj.pkl' if singleobj else 'data_twoobj.pkl'\n",
    "        with open(data_path + file_name, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "    return eeg_multisubj_list, eog_multisubj_list, feat_att_list, feat_unatt_list, gaze_multisubj_list, fs, len_seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_data(subj_path, fsStim, bads, feats_path_folder, singleobj):\n",
    "    PATTERN = subj_path[0].split('/')[-3]\n",
    "    data_path = 'data/' + PATTERN + '/'\n",
    "    file_name = 'data_singleobj.pkl' if singleobj else 'data_twoobj.pkl'\n",
    "    with open(data_path + file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    nb_subj_old = data['eeg_multisubj_list'][0].shape[2]\n",
    "    eeg_multisubj_add, eog_multisubj_add, _, _, gaze_multisubj_add, _, _ = data_multi_subj(subj_path[nb_subj_old:], fsStim, bads[nb_subj_old:], singleobj, feats_path_folder, SAVE=False)\n",
    "    eeg_multisubj_list = [np.concatenate((old, new), axis=2) for old, new in zip(data['eeg_multisubj_list'], eeg_multisubj_add)]\n",
    "    eog_multisubj_list = [np.concatenate((old, new), axis=2) for old, new in zip(data['eog_multisubj_list'], eog_multisubj_add)]\n",
    "    gaze_multisubj_list = [np.concatenate((old, new), axis=2) for old, new in zip(data['gaze_multisubj_list'], gaze_multisubj_add)]\n",
    "    data['eeg_multisubj_list'] = eeg_multisubj_list\n",
    "    data['eog_multisubj_list'] = eog_multisubj_list\n",
    "    data['gaze_multisubj_list'] = gaze_multisubj_list\n",
    "    with open(data_path + file_name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    return eeg_multisubj_list, eog_multisubj_list, data['feat_att_list'], data['feat_unatt_list'], gaze_multisubj_list, data['fs'], data['len_seg_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_shot_cuts(data, fs, time_points=None, remove_time=1):\n",
    "    T = data.shape[0]\n",
    "    if time_points is None:\n",
    "        time_points = [0, T]\n",
    "    nearby_idx = []\n",
    "    for p in time_points:\n",
    "        len_points = int(remove_time*fs)\n",
    "        nearby_idx = nearby_idx + list(range(max(0, p-len_points), min(p+len_points, T)))\n",
    "    nearby_idx = list(set(nearby_idx))\n",
    "    data_clean = np.delete(data, nearby_idx, axis=0)\n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subj_path, fsStim, bads, feats_path_folder, PATTERN, singleobj, LOAD_ONLY, ALL_NEW):\n",
    "    file_name = 'data_singleobj.pkl' if singleobj else 'data_twoobj.pkl'\n",
    "    if LOAD_ONLY:\n",
    "        data_path = 'data/' + PATTERN + '/'\n",
    "        with open(data_path + file_name, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        eeg_multisubj_list = data['eeg_multisubj_list']\n",
    "        eog_multisubj_list = data['eog_multisubj_list']\n",
    "        feat_att_list = data['feat_att_list']\n",
    "        feat_unatt_list = data['feat_unatt_list']\n",
    "        gaze_multisubj_list = data['gaze_multisubj_list']\n",
    "        fs = data['fs']\n",
    "        len_seg_list = data['len_seg_list']\n",
    "    else:\n",
    "        if ALL_NEW:\n",
    "            eeg_multisubj_list, eog_multisubj_list, feat_att_list, feat_unatt_list, gaze_multisubj_list, fs, len_seg_list = data_multi_subj(subj_path, fsStim, bads, singleobj, feats_path_folder)\n",
    "        else:\n",
    "            eeg_multisubj_list, eog_multisubj_list, feat_att_list, feat_unatt_list, gaze_multisubj_list, fs, len_seg_list = add_new_data(subj_path, fsStim, bads, feats_path_folder, singleobj)\n",
    "    return eeg_multisubj_list, eog_multisubj_list, feat_att_list, feat_unatt_list, gaze_multisubj_list, fs, len_seg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the alignment between eog and gaze. The synchronization is good if the peaks of two signals (eye blinks) are aligned.\n",
    "def check_alignment(subj_ID, eog_multisubj_list, gaze_multisubj_list, nb_points=500):\n",
    "    eog_one_subj_list = [eog[:,:,subj_ID] for eog in eog_multisubj_list]\n",
    "    gaze_one_subj_list = [gaze[:,:,subj_ID] for gaze in gaze_multisubj_list]\n",
    "    eog_verti_list = [eog[:,0] - eog[:,1] for eog in eog_one_subj_list]\n",
    "    gaze_y_list = [gaze[:,1] for gaze in gaze_one_subj_list]\n",
    "    nb_videos = len(eog_verti_list)\n",
    "    # make a subplot (3 x (nb_videos//3+1)) for each video\n",
    "    plt.close()\n",
    "    nb_rows = 3\n",
    "    nb_cols = nb_videos//3+1\n",
    "    fig, ax = plt.subplots(nb_rows, nb_cols, figsize=(15, 10))\n",
    "    for i in range(nb_videos):\n",
    "        ax[i//nb_cols, i%nb_cols].plot(eog_verti_list[i][-nb_points:]/np.max(eog_verti_list[i][-nb_points:]), label='eog vertical')\n",
    "        ax[i//nb_cols, i%nb_cols].plot(gaze_y_list[i][-nb_points:]/np.max(gaze_y_list[i][-nb_points:]), label='gaze y')\n",
    "        ax[i//nb_cols, i%nb_cols].set_title('Video ' + str(i+1))\n",
    "        ax[i//nb_cols, i%nb_cols].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['Pilot_1', 'Pilot_2', 'Pilot_4', 'Pilot_5']\n",
    "PATTERN = 'Overlay'\n",
    "subj_path = ['../../Experiments/data/Two_Obj/' + PATTERN + '/' + sub + '/' for sub in subjects]\n",
    "nb_subj = len(subjects)\n",
    "bads = [['A30', 'B25'], ['B25'], ['B25'], []] \n",
    "fsStim = 30\n",
    "feats_path_folder = '../Feat_Multi/features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "singleobj = False\n",
    "eeg_multisubj_list, eog_multisubj_list, feat_all_att_list, feat_all_unatt_list, gaze_multisubj_list, fs, len_seg_list = load_data(subj_path, fsStim, bads, feats_path_folder, PATTERN, singleobj, LOAD_ONLY=False, ALL_NEW=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the alignment between eog and gaze. The synchronization is good if the peaks of two signals (eye blinks) are aligned.\n",
    "subj_to_check = 'Pilot_5'\n",
    "subj_ID = subjects.index(subj_to_check)\n",
    "check_alignment(subj_ID, eog_multisubj_list, gaze_multisubj_list, nb_points=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RemoveSC = True\n",
    "if RemoveSC:\n",
    "    eeg_multisubj_list = [remove_shot_cuts(eeg, fs) for eeg in eeg_multisubj_list]\n",
    "    eog_multisubj_list = [remove_shot_cuts(eog, fs) for eog in eog_multisubj_list]\n",
    "    gaze_multisubj_list = [remove_shot_cuts(gaze, fs) for gaze in gaze_multisubj_list]\n",
    "    feat_all_att_list = [remove_shot_cuts(feat, fs) for feat in feat_all_att_list]\n",
    "    if not singleobj:\n",
    "        feat_all_unatt_list = [remove_shot_cuts(feat, fs) for feat in feat_all_unatt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_band_list = [utils.extract_freq_band(eeg, fsStim, band=[0.1,5]) for eeg in eeg_multisubj_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objflow_att_list = [feats[:,8] for feats in feat_all_att_list]\n",
    "objtempctr_att_list = [feats[:,17] for feats in feat_all_att_list]\n",
    "if not singleobj:\n",
    "    objflow_unatt_list = [feats[:,8] for feats in feat_all_unatt_list]\n",
    "    objtempctr_unatt_list = [feats[:,17] for feats in feat_all_unatt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objflow_att = np.concatenate(objflow_att_list, axis=0)\n",
    "objtempctr_att = np.concatenate(objtempctr_att_list, axis=0)\n",
    "if not singleobj:\n",
    "    objflow_unatt = np.concatenate(objflow_unatt_list, axis=0)\n",
    "    objtempctr_unatt = np.concatenate(objtempctr_unatt_list, axis=0)\n",
    "    # calculate the correlation between objflow_att and objflow_unatt\n",
    "    print(np.corrcoef(objflow_att, objflow_unatt)[0,1])\n",
    "    # calculate the correlation between objtempctr_att and objtempctr_unatt\n",
    "    print(np.corrcoef(objtempctr_att, objtempctr_unatt)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_EEG = 3 \n",
    "L_Stim = int(fsStim/2) \n",
    "offset_EEG = 1 \n",
    "offset_Stim = 0 \n",
    "trial_len_list = list(range(5, 125, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path = 'figures/' + PATTERN + '/SingleObj/' if singleobj else 'figures/' + PATTERN + '/TwoObj/'\n",
    "if not os.path.exists(figure_path):\n",
    "    os.makedirs(figure_path)\n",
    "table_path = 'tables/' + PATTERN + '/SingleObj/' if singleobj else 'tables/' + PATTERN + '/TwoObj/'\n",
    "if not os.path.exists(table_path):\n",
    "    os.makedirs(table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode=Compete: Discriminating between attended and unattended segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_att_or_unatt(Subj_ID, eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT, figure_dir=None, trial_len=60, fold=5, n_components=5, nb_comp_into_account=2, PLOT=False, signifi_level=True, message=True):\n",
    "    eeg_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_multisubj_list]\n",
    "    CCA = algo.CanonicalCorrelationAnalysis(eeg_onesubj_list, feat_att_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, fold=fold, n_components=n_components, signifi_level=signifi_level, message=message)\n",
    "    corr_att_fold, corr_unatt_fold, V_eeg_train, V_feat_train, sig_corr_att, sig_corr_unatt = CCA.att_or_unatt(feat_unatt_list, trial_len=trial_len, TRAIN_WITH_ATT=TRAIN_WITH_ATT)\n",
    "    acc, p_value, acc_sig, corr_att_cv, corr_unatt_cv= utils.eval_compete(corr_att_fold, corr_unatt_fold, nb_comp_into_account)\n",
    "    if PLOT:\n",
    "        # find the indices components with corr > sig_corr\n",
    "        idx_sig_att = np.where(corr_att_cv > sig_corr_att)[0]\n",
    "        idx_sig_unatt = np.where(corr_unatt_cv > sig_corr_unatt)[0]\n",
    "        figure_name_att = figure_dir + 'Subj_' + str(Subj_ID) + '_Trial_len_' + str(trial_len) +  '_Train_Att_Test_Att.png' if TRAIN_WITH_ATT else figure_dir + 'Subj_' + str(Subj_ID) + '_Trial_len_' + str(trial_len) + '_Train_Unatt_Test_Att.png'\n",
    "        figure_name_unatt = figure_dir + 'Subj_' + str(Subj_ID) + '_Trial_len_' + str(trial_len) + '_Train_Att_Test_Unatt.png' if TRAIN_WITH_ATT else figure_dir + 'Subj_' + str(Subj_ID) + '_Trial_len_' + str(trial_len) + '_Train_Unatt_Test_Unatt.png'\n",
    "        eeg_onesub = np.concatenate(tuple(eeg_onesubj_list), axis=0)\n",
    "        forward_model = CCA.forward_model(eeg_onesub, V_eeg_train)\n",
    "        utils.plot_spatial_resp(forward_model, corr_att_fold, figure_name_att, idx_sig=idx_sig_att)\n",
    "        utils.plot_spatial_resp(forward_model, corr_unatt_fold, figure_name_unatt, idx_sig=idx_sig_unatt)\n",
    "    return acc, p_value, acc_sig, corr_att_cv, corr_unatt_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_compete_trials(Subj_ID, eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir, fold=5, n_components=5, nb_comp_into_account=2):\n",
    "    acc_list = []\n",
    "    p_value_list = []\n",
    "    acc_sig_list = []\n",
    "    for trial_len in trial_len_list:\n",
    "        print('Trial length: ', trial_len)\n",
    "        acc, p_value, acc_sig, _, _ = pipe_att_or_unatt(Subj_ID, eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=True, trial_len=trial_len, fold=fold, n_components=n_components, nb_comp_into_account=nb_comp_into_account, signifi_level=False, message=False)\n",
    "        acc_list.append(acc)\n",
    "        p_value_list.append(p_value)\n",
    "        acc_sig_list.append(acc_sig)\n",
    "        # save the results\n",
    "    results = {'acc': acc_list, 'pvalue': p_value_list, 'acc_sig': acc_sig_list, 'trial_len_list': trial_len_list}\n",
    "    table_name = table_dir + 'Subj_' + str(Subj_ID) + '_compete.pkl'\n",
    "    with open(table_name, 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_att_list = objflow_att_list\n",
    "feat_unatt_list = objflow_unatt_list\n",
    "figure_dir_EEG = figure_path + '/EEG/'\n",
    "if not os.path.exists(figure_dir_EEG):\n",
    "    os.makedirs(figure_dir_EEG)\n",
    "table_dir_EEG = table_path + '/EEG/'\n",
    "if not os.path.exists(table_dir_EEG):\n",
    "    os.makedirs(table_dir_EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subj_ID = 3\n",
    "acc, p_value, acc_sig, corr_att_cv, corr_unatt_cv= pipe_att_or_unatt(Subj_ID, eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=True, figure_dir=figure_dir_EEG, trial_len=60, PLOT=True)\n",
    "acc, p_value, acc_sig, corr_att_cv, corr_unatt_cv = pipe_att_or_unatt(Subj_ID, eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=False, figure_dir=figure_dir_EEG, trial_len=60, PLOT=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_compete_trials(Subj_ID, eeg_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir_EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode=Match-Mismatch: Discriminating between match and mismatch segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_mm_trials(Subj_ID, eeg_multisubj_list, feat_match_list, feat_distract_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir, MATCHATT, fold=5, n_components=5, nb_comp_into_account=2):\n",
    "    acc_list = []\n",
    "    p_value_list = []\n",
    "    eeg_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_multisubj_list]\n",
    "    for trial_len in trial_len_list:\n",
    "        print('Trial length: ', trial_len)\n",
    "        CCA = algo.CanonicalCorrelationAnalysis(eeg_onesubj_list, feat_match_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, fold=fold, n_components=n_components, signifi_level=False, message=False)\n",
    "        corr_tensor_list = CCA.match_mismatch(trial_len, feat_distract_list)\n",
    "        acc, p_value = utils.eval_mm(corr_tensor_list, nb_comp_into_account)\n",
    "        print('Accuracy: ', acc, 'P-value: ', p_value)\n",
    "        acc_list.append(acc)\n",
    "        p_value_list.append(p_value)\n",
    "        # save the results\n",
    "    results = {'acc': acc_list, 'pvalue': p_value_list, 'trial_len_list': trial_len_list}\n",
    "    table_name = table_dir + 'Subj_' + str(Subj_ID) + '_match_att.pkl' if MATCHATT else table_dir + 'Subj_' + str(Subj_ID) + '_match_unatt.pkl'\n",
    "    with open(table_name, 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dir_EEG = table_path + '/EEG/'\n",
    "if not os.path.exists(table_dir_EEG):\n",
    "    os.makedirs(table_dir_EEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subj_ID = 3\n",
    "feat_match_list = objflow_att_list\n",
    "feat_distract_list = objflow_unatt_list\n",
    "MATCHATT = True\n",
    "pipe_mm_trials(Subj_ID, eeg_multisubj_list, feat_match_list, feat_distract_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir_EEG, MATCHATT, fold=5, n_components=5, nb_comp_into_account=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subj_ID = 3\n",
    "feat_match_list = objflow_unatt_list\n",
    "feat_distract_list = objflow_att_list\n",
    "MATCHATT = False\n",
    "pipe_mm_trials(Subj_ID, eeg_multisubj_list, feat_match_list, feat_distract_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir_EEG, MATCHATT, fold=5, n_components=5, nb_comp_into_account=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results\n",
    "Subj_ID = 3\n",
    "with open(table_dir_EEG + 'Subj_' + str(Subj_ID) + '_compete.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    acc_list_compete = results['acc']\n",
    "    p_values_list_compete = results['pvalue']\n",
    "    acc_sig_list = results['acc_sig']\n",
    "    trial_len_list = results['trial_len_list']\n",
    "with open(table_dir_EEG + 'Subj_' + str(Subj_ID) + '_match_att.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    acc_list_match_att = results['acc']\n",
    "    p_values_list_match_att = results['pvalue']\n",
    "with open(table_dir_EEG + 'Subj_' + str(Subj_ID) + '_match_unatt.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    acc_list_match_unatt = results['acc']\n",
    "    p_values_list_match_unatt = results['pvalue']\n",
    "\n",
    "plt.close()\n",
    "# Plot lines\n",
    "plt.plot(trial_len_list, acc_list_compete, label='Competing')\n",
    "plt.plot(trial_len_list, acc_list_match_att, label='Matching-Att')\n",
    "plt.plot(trial_len_list, acc_list_match_unatt, label='Matching-Unatt')\n",
    "plt.plot(trial_len_list, acc_sig_list, label='Significance level', linestyle='--')\n",
    "\n",
    "# Assuming p_values_list, p_values_list_unatt_permu, and p_values_list_permu_att are the lists of p-values for each condition\n",
    "# Plot circles where p-value < 0.05\n",
    "for trial_len, acc, p_value in zip(trial_len_list, acc_list_compete, p_values_list_compete):\n",
    "    if p_value > 0.05:\n",
    "        plt.scatter(trial_len, acc, edgecolors='red', facecolors='none', s=100)\n",
    "\n",
    "for trial_len, acc, p_value in zip(trial_len_list, acc_list_match_att, p_values_list_match_att):\n",
    "    if p_value > 0.05:\n",
    "        plt.scatter(trial_len, acc, edgecolors='red', facecolors='none', s=100)\n",
    "\n",
    "for trial_len, acc, p_value in zip(trial_len_list, acc_list_match_unatt, p_values_list_match_unatt):\n",
    "    if p_value > 0.05:\n",
    "        plt.scatter(trial_len, acc, edgecolors='red', facecolors='none', s=100)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Segment length (s)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Subject ' + str(Subj_ID+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using EOG signals or eye tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_att_list = objflow_att_list\n",
    "feat_unatt_list = objflow_unatt_list\n",
    "figure_dir_EOG= figure_path + '/EOG/'\n",
    "if not os.path.exists(figure_dir_EOG):\n",
    "    os.makedirs(figure_dir_EOG)\n",
    "table_dir_EOG = table_path + '/EOG/'\n",
    "if not os.path.exists(table_dir_EOG):\n",
    "    os.makedirs(table_dir_EOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subj_ID = 3\n",
    "acc, p_value, acc_sig, corr_att_cv, corr_unatt_cv= pipe_att_or_unatt(Subj_ID, eog_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=True, figure_dir=figure_dir_EOG, trial_len=60, PLOT=False)\n",
    "acc, p_value, acc_sig, corr_att_cv, corr_unatt_cv = pipe_att_or_unatt(Subj_ID, eog_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=False, figure_dir=figure_dir_EOG, trial_len=60, PLOT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_compete_trials(Subj_ID, eog_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir_EOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_att_list = objflow_att_list\n",
    "feat_unatt_list = objflow_unatt_list\n",
    "figure_dir_ET= figure_path + '/ET/'\n",
    "if not os.path.exists(figure_dir_ET):\n",
    "    os.makedirs(figure_dir_ET)\n",
    "table_dir_ET = table_path + '/ET/'\n",
    "if not os.path.exists(table_dir_ET):\n",
    "    os.makedirs(table_dir_ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subj_ID = 3\n",
    "acc, p_value, acc_sig, corr_att_cv, corr_unatt_cv= pipe_att_or_unatt(Subj_ID, gaze_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=True, figure_dir=figure_dir_ET, trial_len=60, PLOT=False)\n",
    "acc, p_value, acc_sig, corr_att_cv, corr_unatt_cv = pipe_att_or_unatt(Subj_ID, gaze_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, TRAIN_WITH_ATT=False, figure_dir=figure_dir_ET, trial_len=60, PLOT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_compete_trials(Subj_ID, gaze_multisubj_list, feat_att_list, feat_unatt_list, fs, L_EEG, L_Stim, offset_EEG, offset_Stim, trial_len_list, table_dir_ET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results\n",
    "Subj_ID = 3\n",
    "with open(table_dir_EEG + 'Subj_' + str(Subj_ID) + '_compete.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    acc_list_EEG = results['acc']\n",
    "    p_values_list_EEG = results['pvalue']\n",
    "    acc_sig_list = results['acc_sig']\n",
    "    trial_len_list = results['trial_len_list']\n",
    "with open(table_dir_EOG + 'Subj_' + str(Subj_ID) + '_compete.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    acc_list_EOG = results['acc']\n",
    "    p_values_list_EOG = results['pvalue']\n",
    "with open(table_dir_ET + 'Subj_' + str(Subj_ID) + '_compete.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "    acc_list_ET = results['acc']\n",
    "    p_values_list_ET = results['pvalue']\n",
    "\n",
    "\n",
    "plt.close()\n",
    "# Plot lines\n",
    "plt.plot(trial_len_list, acc_list_EEG, label='EEG')\n",
    "plt.plot(trial_len_list, acc_list_EOG, label='EOG')\n",
    "plt.plot(trial_len_list, acc_list_ET, label='Eye tracker')\n",
    "plt.plot(trial_len_list, acc_sig_list, label='Significance level', linestyle='--')\n",
    "\n",
    "# Assuming p_values_list, p_values_list_unatt_permu, and p_values_list_permu_att are the lists of p-values for each condition\n",
    "# Plot circles where p-value < 0.05\n",
    "for trial_len, acc, p_value in zip(trial_len_list, acc_list_EEG, p_values_list_EEG):\n",
    "    if p_value > 0.05:\n",
    "        plt.scatter(trial_len, acc, edgecolors='red', facecolors='none', s=100)\n",
    "\n",
    "for trial_len, acc, p_value in zip(trial_len_list, acc_list_EOG, p_values_list_EOG):\n",
    "    if p_value > 0.05:\n",
    "        plt.scatter(trial_len, acc, edgecolors='red', facecolors='none', s=100)\n",
    "\n",
    "for trial_len, acc, p_value in zip(trial_len_list, acc_list_ET, p_values_list_ET):\n",
    "    if p_value > 0.05:\n",
    "        plt.scatter(trial_len, acc, edgecolors='red', facecolors='none', s=100)\n",
    "plt.legend()\n",
    "plt.xlabel('Segment length (s)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Subject ' + str(Subj_ID+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations between EEG signals when looking at the same video pairs but attending different objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_eeg = 3\n",
    "offset_eeg = 1\n",
    "eeg_set1_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_set1_list]\n",
    "eeg_set2_onesubj_list = [eeg[:,:,Subj_ID] for eeg in eeg_set2_list]\n",
    "CCA = algo.CanonicalCorrelationAnalysis(eeg_set1_onesubj_list, eeg_set2_onesubj_list, fsStim, L_eeg, L_eeg, offset_eeg, offset_eeg, fold=5, signifi_level=True, n_components=5)\n",
    "_, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the EEG signals of different subjects together (along the time axis)\n",
    "def concat_multi_subj_eeg(eeg_multisubj):\n",
    "    _, _, nb_subj = eeg_multisubj.shape\n",
    "    eeg_subj_list = [eeg_multisubj[:,:,i] for i in range(nb_subj)]\n",
    "    eeg_concat = np.concatenate(tuple(eeg_subj_list), axis=0)\n",
    "    return eeg_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_set1_array_list = [concat_multi_subj_eeg(eeg) for eeg in eeg_set1_list]\n",
    "eeg_set2_array_list = [concat_multi_subj_eeg(eeg) for eeg in eeg_set2_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCA = algo.CanonicalCorrelationAnalysis(eeg_set1_array_list, eeg_set2_array_list, fsStim, L_eeg, L_eeg, offset_eeg, offset_eeg, fold=5, signifi_level=True, n_components=5)\n",
    "_, corr_test, sig_corr, _, tsc_test, _, _, V_A_train, V_B_train = CCA.cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_set1_set2_tensor_list = [np.concatenate((eeg_set1, eeg_set2), axis=2) for eeg_set1, eeg_set2 in zip(eeg_set1_list, eeg_set2_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCCA = algo.GeneralizedCCA(eeg_set1_set2_tensor_list, fs, L=5, offset=2, n_components=10, signifi_level=True, trials=True)\n",
    "corr_train, corr_test, cov_train, cov_test, tsc_train, tsc_test, dist_train, dist_test, W_train, F_train_GCCA = GCCA.cross_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_spatial_resp(F_train_GCCA, corr_test, 'set1_set2.pdf', ifISC=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
